{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomaszwk/NLP/blob/main/desafio2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZd5yLnnHOK0"
      },
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## Custom embedddings con Gensim\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vA7nqkumo9z9"
      },
      "source": [
        "### Objetivo\n",
        "El objetivo es utilizar documentos / corpus para crear embeddings de palabras basado en ese contexto. Se utilizará canciones de bandas para generar los embeddings, es decir, que los vectores tendrán la forma en función de como esa banda haya utilizado las palabras en sus canciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lFToQs5FK5uZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import multiprocessing\n",
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g07zJxG7H9vG"
      },
      "source": [
        "### Datos\n",
        "Utilizaremos como dataset canciones de bandas de habla inglesa."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "# URL del libro en formato txt desde el Proyecto Gutenberg\n",
        "url = 'https://www.gutenberg.org/files/2701/2701-0.txt'  # Ejemplo con \"Moby Dick\" de Herman Melville\n",
        "\n",
        "# Nombre del archivo donde se guardará el libro\n",
        "filename = 'moby_dick.txt'\n",
        "\n",
        "# Verificar si el archivo ya existe\n",
        "if not os.path.exists(filename):\n",
        "    print(\"Descargando el libro desde el Proyecto Gutenberg...\")\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        with open(filename, 'wb') as file:\n",
        "            file.write(response.content)\n",
        "        print(f'El libro se ha descargado y guardado como {filename}')\n",
        "    else:\n",
        "        print(\"Hubo un problema al descargar el libro.\")\n",
        "else:\n",
        "    print(f\"El archivo '{filename}' ya existe.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iCQ3CaFHwP9",
        "outputId": "80e6327c-a292-4473-8071-db7dacc92aae"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El archivo 'moby_dick.txt' ya existe.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ticoqYD1Z3I7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "6e4f9b1f-ec60-4579-e808-7a34fb0168f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Sentence\n",
              "0  ﻿The Project Gutenberg eBook of Moby-Dick; or ...\n",
              "1  You may copy it, give it away or re-use it und...\n",
              "2  If you are not located in the United States, y...\n",
              "3  Title: Moby-Dick; or The Whale\\n\\nAuthor: Herm...\n",
              "4   By Herman Melville\\n\\n\\n\\nCONTENTS\\n\\nETYMOLOGY."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-336d914e-6fc8-457f-950b-9722a8adec5b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>﻿The Project Gutenberg eBook of Moby-Dick; or ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>You may copy it, give it away or re-use it und...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>If you are not located in the United States, y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Title: Moby-Dick; or The Whale\\n\\nAuthor: Herm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>By Herman Melville\\n\\n\\n\\nCONTENTS\\n\\nETYMOLOGY.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-336d914e-6fc8-457f-950b-9722a8adec5b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-336d914e-6fc8-457f-950b-9722a8adec5b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-336d914e-6fc8-457f-950b-9722a8adec5b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0fce83b0-cc57-45f5-9218-0ef511991333\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0fce83b0-cc57-45f5-9218-0ef511991333')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0fce83b0-cc57-45f5-9218-0ef511991333 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 9181,\n  \"fields\": [\n    {\n      \"column\": \"Sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8788,\n        \"samples\": [\n          \"If I\\nhad been downright honest with myself, I would have seen very plainly\\nin my heart that I did but half fancy being committed this way to so\\nlong a voyage, without once laying my eyes on the man who was to be the\\nabsolute dictator of it, so soon as the ship sailed out upon the open\\nsea.\",\n          \"This peculiarity is most vividly\\nhit by the French in the name they bestow upon that fish.\",\n          \"But in brief, they are these: lungs and warm blood;\\nwhereas, all other fish are lungless and cold blooded.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Armar el dataset utilizando salto de línea para separar las oraciones/docs\n",
        "import nltk\n",
        "import pandas as pd\n",
        "\n",
        "# Descargar el tokenizador de oraciones\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Leer el contenido del archivo 'moby_dick.txt'\n",
        "with open('moby_dick.txt', 'r', encoding='utf-8') as file:\n",
        "    text = file.read()\n",
        "\n",
        "# Separar el texto en oraciones\n",
        "sentences = nltk.sent_tokenize(text)\n",
        "\n",
        "# Crear un DataFrame con cada oración como una fila\n",
        "df = pd.DataFrame(sentences, columns=['Sentence'])\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LEpKubK9XzXN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b828ddd-5003-498c-f6aa-a19eb982b787"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de documentos: 9181\n"
          ]
        }
      ],
      "source": [
        "print(\"Cantidad de documentos:\", df.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab94qaFlrA1G"
      },
      "source": [
        "### 1 - Preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install Keras==2.12.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7B-HKG_FJP9",
        "outputId": "45a4ac1b-5724-4bf6-af85-4d4388b2072f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Keras==2.12.0\n",
            "  Using cached keras-2.12.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Using cached keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "Installing collected packages: Keras\n",
            "  Attempting uninstall: Keras\n",
            "    Found existing installation: keras 2.10.0\n",
            "    Uninstalling keras-2.10.0:\n",
            "      Successfully uninstalled keras-2.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.10.0 requires keras<2.11,>=2.10.0, but you have keras 2.12.0 which is incompatible.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Keras-2.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow==2.10.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcAXVnZFF9lZ",
        "outputId": "4534d236-d52f-4f78-a9a7-945f09b6007d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.10.0 in /usr/local/lib/python3.10/dist-packages (2.10.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (24.3.25)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.64.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (3.11.0)\n",
            "Collecting keras<2.11,>=2.10.0 (from tensorflow==2.10.0)\n",
            "  Using cached keras-2.10.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.1.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (18.1.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (24.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (3.19.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.11,>=2.10 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (2.10.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (0.37.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (2.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.16.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.10.0) (0.44.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.2.2)\n",
            "Using cached keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
            "Installing collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-2.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rIsmMWmjrDHd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "350ed95d-b2e6-48d6-fac4-667c64ce4b9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-4bb61bf6ad25>:7: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  sentence_tokens.append(text_to_word_sequence(row[0]))\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "\n",
        "sentence_tokens = []\n",
        "# Recorrer todas las filas y transformar las oraciones\n",
        "# en una secuencia de palabras (esto podría realizarse con NLTK o spaCy también)\n",
        "for _, row in df[:None].iterrows():\n",
        "    sentence_tokens.append(text_to_word_sequence(row[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaXV6nlHr5Aa"
      },
      "source": [
        "### 2 - Crear los vectores (word2vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OSb0v7h8r7hK"
      },
      "outputs": [],
      "source": [
        "from gensim.models.callbacks import CallbackAny2Vec\n",
        "# Durante el entrenamiento gensim por defecto no informa el \"loss\" en cada época\n",
        "# Sobrecargamos el callback para poder tener esta información\n",
        "class callback(CallbackAny2Vec):\n",
        "    \"\"\"\n",
        "    Callback to print loss after each epoch\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.epoch = 0\n",
        "\n",
        "    def on_epoch_end(self, model):\n",
        "        loss = model.get_latest_training_loss()\n",
        "        if self.epoch == 0:\n",
        "            print('Loss after epoch {}: {}'.format(self.epoch, loss))\n",
        "        else:\n",
        "            print('Loss after epoch {}: {}'.format(self.epoch, loss- self.loss_previous_step))\n",
        "        self.epoch += 1\n",
        "        self.loss_previous_step = loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "i0wnDdv9sJ47"
      },
      "outputs": [],
      "source": [
        "# Crearmos el modelo generador de vectores\n",
        "# En este caso utilizaremos la estructura modelo Skipgram\n",
        "w2v_model = Word2Vec(min_count=5,    # frecuencia mínima de palabra para incluirla en el vocabulario\n",
        "                     window=2,       # cant de palabras antes y desp de la predicha\n",
        "                     vector_size=300,       # dimensionalidad de los vectores\n",
        "                     negative=20,    # cantidad de negative samples... 0 es no se usa\n",
        "                     workers=4,      # si tienen más cores pueden cambiar este valor\n",
        "                     sg=1)           # modelo 0:CBOW  1:skipgram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5lTt8wErsf17"
      },
      "outputs": [],
      "source": [
        "# Obtener el vocabulario con los tokens\n",
        "w2v_model.build_vocab(sentence_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "TNc9qt4os5AT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "297b636c-3a79-4def-8614-ed480576038e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de docs en el corpus: 9181\n"
          ]
        }
      ],
      "source": [
        "# Cantidad de filas/docs encontradas en el corpus\n",
        "print(\"Cantidad de docs en el corpus:\", w2v_model.corpus_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "idw9cHF3tSMl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "391d9c79-d777-40d8-a24c-23a402eb31b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de words distintas en el corpus: 4381\n"
          ]
        }
      ],
      "source": [
        "# Cantidad de words encontradas en el corpus\n",
        "print(\"Cantidad de words distintas en el corpus:\", len(w2v_model.wv.index_to_key))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC9mZ8DPk-UC"
      },
      "source": [
        "### 3 - Entrenar embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QSp-x0PAsq56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98eb4221-7921-488f-cbad-8a2682718d92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss after epoch 0: 504874.53125\n",
            "Loss after epoch 1: 414125.96875\n",
            "Loss after epoch 2: 379576.75\n",
            "Loss after epoch 3: 360688.0\n",
            "Loss after epoch 4: 353034.125\n",
            "Loss after epoch 5: 320481.375\n",
            "Loss after epoch 6: 308732.25\n",
            "Loss after epoch 7: 307454.0\n",
            "Loss after epoch 8: 306179.5\n",
            "Loss after epoch 9: 301542.25\n",
            "Loss after epoch 10: 297084.25\n",
            "Loss after epoch 11: 299147.5\n",
            "Loss after epoch 12: 277231.5\n",
            "Loss after epoch 13: 269809.5\n",
            "Loss after epoch 14: 263853.5\n",
            "Loss after epoch 15: 265168.5\n",
            "Loss after epoch 16: 261875.0\n",
            "Loss after epoch 17: 261576.5\n",
            "Loss after epoch 18: 259738.0\n",
            "Loss after epoch 19: 257846.5\n",
            "Loss after epoch 20: 256516.5\n",
            "Loss after epoch 21: 252539.5\n",
            "Loss after epoch 22: 255171.0\n",
            "Loss after epoch 23: 249330.5\n",
            "Loss after epoch 24: 247070.0\n",
            "Loss after epoch 25: 245017.5\n",
            "Loss after epoch 26: 249091.0\n",
            "Loss after epoch 27: 245378.0\n",
            "Loss after epoch 28: 235628.5\n",
            "Loss after epoch 29: 226839.0\n",
            "Loss after epoch 30: 229077.0\n",
            "Loss after epoch 31: 224223.0\n",
            "Loss after epoch 32: 223696.0\n",
            "Loss after epoch 33: 224534.0\n",
            "Loss after epoch 34: 220620.0\n",
            "Loss after epoch 35: 218910.0\n",
            "Loss after epoch 36: 222499.0\n",
            "Loss after epoch 37: 225830.0\n",
            "Loss after epoch 38: 218803.0\n",
            "Loss after epoch 39: 217811.0\n",
            "Loss after epoch 40: 215564.0\n",
            "Loss after epoch 41: 220760.0\n",
            "Loss after epoch 42: 217958.0\n",
            "Loss after epoch 43: 216431.0\n",
            "Loss after epoch 44: 215385.0\n",
            "Loss after epoch 45: 213585.0\n",
            "Loss after epoch 46: 216755.0\n",
            "Loss after epoch 47: 215382.0\n",
            "Loss after epoch 48: 218329.0\n",
            "Loss after epoch 49: 210853.0\n",
            "Loss after epoch 50: 214342.0\n",
            "Loss after epoch 51: 211958.0\n",
            "Loss after epoch 52: 214588.0\n",
            "Loss after epoch 53: 214597.0\n",
            "Loss after epoch 54: 209593.0\n",
            "Loss after epoch 55: 245484.0\n",
            "Loss after epoch 56: 213922.0\n",
            "Loss after epoch 57: 212633.0\n",
            "Loss after epoch 58: 207363.0\n",
            "Loss after epoch 59: 208563.0\n",
            "Loss after epoch 60: 210271.0\n",
            "Loss after epoch 61: 214649.0\n",
            "Loss after epoch 62: 206646.0\n",
            "Loss after epoch 63: 209631.0\n",
            "Loss after epoch 64: 206245.0\n",
            "Loss after epoch 65: 209841.0\n",
            "Loss after epoch 66: 203491.0\n",
            "Loss after epoch 67: 190253.0\n",
            "Loss after epoch 68: 192244.0\n",
            "Loss after epoch 69: 188362.0\n",
            "Loss after epoch 70: 187224.0\n",
            "Loss after epoch 71: 185590.0\n",
            "Loss after epoch 72: 191586.0\n",
            "Loss after epoch 73: 188720.0\n",
            "Loss after epoch 74: 183812.0\n",
            "Loss after epoch 75: 187740.0\n",
            "Loss after epoch 76: 185750.0\n",
            "Loss after epoch 77: 183672.0\n",
            "Loss after epoch 78: 186990.0\n",
            "Loss after epoch 79: 183980.0\n",
            "Loss after epoch 80: 185710.0\n",
            "Loss after epoch 81: 182582.0\n",
            "Loss after epoch 82: 181140.0\n",
            "Loss after epoch 83: 186274.0\n",
            "Loss after epoch 84: 184888.0\n",
            "Loss after epoch 85: 183110.0\n",
            "Loss after epoch 86: 181390.0\n",
            "Loss after epoch 87: 179744.0\n",
            "Loss after epoch 88: 183020.0\n",
            "Loss after epoch 89: 180934.0\n",
            "Loss after epoch 90: 213860.0\n",
            "Loss after epoch 91: 183290.0\n",
            "Loss after epoch 92: 181034.0\n",
            "Loss after epoch 93: 181202.0\n",
            "Loss after epoch 94: 179666.0\n",
            "Loss after epoch 95: 176536.0\n",
            "Loss after epoch 96: 175516.0\n",
            "Loss after epoch 97: 176056.0\n",
            "Loss after epoch 98: 178638.0\n",
            "Loss after epoch 99: 175608.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14135305, 22077100)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Entrenamos el modelo generador de vectores\n",
        "# Utilizamos nuestro callback\n",
        "w2v_model.train(sentence_tokens,\n",
        "                 total_examples=w2v_model.corpus_count,\n",
        "                 epochs=100,\n",
        "                 compute_loss = True,\n",
        "                 callbacks=[callback()]\n",
        "                 )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddT9NVuNlCAe"
      },
      "source": [
        "### 4 - Ensayar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6cHN9xGLuPEm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92d9b243-35d6-445e-abeb-0a4283fef565"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('“hast', 0.3810027837753296),\n",
              " ('killer', 0.33427926898002625),\n",
              " ('designated', 0.32033321261405945),\n",
              " ('beale’s', 0.31745684146881104),\n",
              " ('feat', 0.3078577220439911),\n",
              " ('v', 0.3053145706653595),\n",
              " ('scoresby', 0.3053103983402252),\n",
              " ('frederick', 0.3043726682662964),\n",
              " ('authorities', 0.29904332756996155),\n",
              " ('technically', 0.29787224531173706)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Palabras que MÁS se relacionan con...:\n",
        "w2v_model.wv.most_similar(positive=[\"whale\"], topn=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "47HiU5gdkdMq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8e7832e-dd9b-491e-8d3c-e4cbcb1d26a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('stepping', 0.05092572420835495),\n",
              " ('during', 0.050820983946323395),\n",
              " ('thigh', 0.047357380390167236),\n",
              " ('caw', 0.04567653313279152),\n",
              " ('subject', 0.04554687440395355),\n",
              " ('links', 0.04429538547992706),\n",
              " ('beneath', 0.04298143461346626),\n",
              " ('slender', 0.04060402140021324),\n",
              " ('wholly', 0.03290611878037453),\n",
              " ('means', 0.030932491645216942)]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Palabras que MENOS se relacionan con...:\n",
        "w2v_model.wv.most_similar(negative=[\"love\"], topn=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "DT4Rvno2mD65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "003f9deb-4442-4336-adc6-380919da11aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('goin’', 0.37935659289360046),\n",
              " ('twenty', 0.37709060311317444),\n",
              " ('years’', 0.36710086464881897),\n",
              " ('five', 0.35121291875839233),\n",
              " ('ridge', 0.34427475929260254),\n",
              " ('sixty', 0.3423555791378021),\n",
              " ('eighteen', 0.3414296805858612),\n",
              " ('six', 0.33636417984962463),\n",
              " ('yards', 0.32665517926216125),\n",
              " ('sorts', 0.3192387819290161)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Palabras que MÁS se relacionan con...:\n",
        "w2v_model.wv.most_similar(positive=[\"four\"], topn=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "XPLDPgzBmQXt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd3cd1ec-d182-4d02-fc99-a4258fd15832"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('replacement', 0.41592031717300415),\n",
              " ('fee', 0.4039054811000824),\n",
              " ('religion', 0.397554874420166),\n",
              " ('refund', 0.39568233489990234),\n",
              " ('cetology', 0.390004962682724)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Palabras que MÁS se relacionan con...:\n",
        "w2v_model.wv.most_similar(positive=[\"money\"], topn=5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Palabras que MÁS se relacionan con...:\n",
        "w2v_model.wv.most_similar(positive=[\"whale\"], topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6Kq86_IO162",
        "outputId": "e02a0c5e-9d48-4818-e064-bdd9f0cc1e6e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('“hast', 0.3810027837753296),\n",
              " ('killer', 0.33427926898002625),\n",
              " ('designated', 0.32033321261405945),\n",
              " ('beale’s', 0.31745684146881104),\n",
              " ('feat', 0.3078577220439911),\n",
              " ('v', 0.3053145706653595),\n",
              " ('scoresby', 0.3053103983402252),\n",
              " ('frederick', 0.3043726682662964),\n",
              " ('authorities', 0.29904332756996155),\n",
              " ('technically', 0.29787224531173706)]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClkGomn7E5Ep",
        "outputId": "f06a05c2-0bf4-4d9d-fa21-18a38c585c49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2.16715887e-01  8.16305280e-01  7.99848884e-03 -7.47073218e-02\n",
            " -8.94432962e-02 -3.67586344e-01 -3.73736113e-01  1.10855305e+00\n",
            " -6.35345221e-01  7.80354679e-01  1.87365621e-01 -6.35256767e-02\n",
            " -1.95903808e-01 -3.00830662e-01 -5.76541089e-02 -4.48966801e-01\n",
            "  5.82650602e-01  8.44676495e-02 -4.37751114e-01  6.73683286e-01\n",
            " -3.27827543e-01 -5.27827203e-01  1.60098553e-01  1.07531726e-01\n",
            " -1.45438686e-01  6.57403171e-02 -3.09369236e-01 -5.50946929e-02\n",
            " -2.32917994e-01 -5.47013022e-02  1.23166554e-01 -2.79419690e-01\n",
            "  3.67711872e-01 -1.82876423e-01  1.87012106e-01 -3.63856941e-01\n",
            " -9.78680700e-02 -2.81137496e-01 -1.06852323e-01 -2.32166559e-01\n",
            " -3.22363563e-02  2.13228628e-01 -4.34457421e-01  2.41892487e-01\n",
            "  5.40572107e-01 -4.05018240e-01  3.47312212e-01 -2.09053576e-01\n",
            " -2.56684601e-01 -1.95138440e-01  9.17125344e-02 -2.68105119e-01\n",
            " -1.13491094e+00  2.59456038e-01  1.61620572e-01  3.54562998e-01\n",
            " -5.39684035e-02 -3.98534656e-01  1.82324827e-01  7.72297323e-01\n",
            "  2.11227059e-01  2.10163102e-01  2.34339058e-01  3.73039961e-01\n",
            " -7.50330985e-01  3.58534992e-01 -8.39165330e-01  2.67389953e-01\n",
            "  1.01139463e-01  6.55191764e-02 -3.12351018e-01  1.91789269e-01\n",
            "  1.71712816e-01 -2.14073002e-01  6.06950879e-01  2.72233874e-01\n",
            "  6.34231091e-01 -1.84093654e-01  5.40289022e-02 -1.87733591e-01\n",
            " -7.67942742e-02 -9.77418497e-02 -2.56575346e-01  6.15063131e-01\n",
            "  2.82237381e-01 -1.94371879e-01 -1.61258012e-01  1.78062677e-01\n",
            "  4.01547045e-01 -2.09651679e-01  2.49712393e-01 -6.37121201e-01\n",
            "  3.14103246e-01  7.84528494e-01 -4.56957161e-01  2.34659865e-01\n",
            "  2.88617313e-02 -6.08535647e-01  3.74928802e-01  6.93994015e-03\n",
            "  1.57149136e-01  1.22119106e-01  1.14494361e-01  3.84712130e-01\n",
            "  1.61147282e-01 -8.20826963e-02  1.12187080e-01 -7.44816288e-02\n",
            " -5.84329367e-01  1.38109121e-02  8.31914619e-02 -4.18694764e-02\n",
            " -5.64091027e-01  4.86846536e-01 -3.93204898e-01 -2.01770782e-01\n",
            "  8.63774538e-01 -6.05905056e-01  8.70171905e-01 -1.33741498e-01\n",
            " -1.42293289e-01  2.66208887e-01 -3.95298183e-01 -5.17923832e-01\n",
            "  1.09912358e-01  5.27620077e-01  3.49698484e-01  2.68493056e-01\n",
            " -4.29730415e-01  7.96398640e-01  1.23428456e-01 -3.95611554e-01\n",
            " -2.33658720e-02 -2.97993809e-01  1.87135547e-01  1.13361798e-01\n",
            "  2.90914923e-01  1.54787526e-01 -1.54978439e-01 -4.63689268e-01\n",
            " -5.16246140e-01 -8.86663914e-01 -2.43262872e-01  1.85574546e-01\n",
            " -4.19890255e-01 -9.18756723e-02  2.54136696e-02 -8.36993679e-02\n",
            "  3.08281064e-01  1.51398391e-01  7.80267894e-01 -4.36555631e-02\n",
            "  2.52844006e-01 -7.75887594e-02 -4.13733661e-01  2.12554932e-01\n",
            " -9.17922795e-01  9.70970169e-02  3.99488240e-01  2.17609346e-01\n",
            " -1.06679308e+00 -4.45855439e-01 -1.10300648e+00 -5.59337139e-02\n",
            "  1.53350115e-01  5.00756085e-01  3.56459618e-01 -2.34127313e-01\n",
            "  4.31573302e-01  3.38284343e-01 -8.04507062e-02  9.00752917e-02\n",
            " -1.91382378e-01 -1.03567123e-01  3.75388891e-01  3.73626411e-01\n",
            " -1.50106505e-01 -4.64268982e-01 -6.38863072e-02 -1.87364295e-02\n",
            "  2.89160341e-01 -3.40494037e-01 -1.76492333e-01 -4.88883913e-01\n",
            " -3.21252167e-01 -6.47509038e-01  2.56933779e-01  2.92604148e-01\n",
            " -3.37121859e-02 -1.21833356e-02  1.61483902e-02 -5.51964603e-02\n",
            "  1.47716049e-03 -1.45850837e-01 -7.03493655e-01  2.33042628e-01\n",
            " -3.31100613e-01 -4.66381162e-01 -7.17497319e-02 -1.21272214e-01\n",
            " -7.59296775e-01  3.54141057e-01  3.21240902e-01  1.76842824e-01\n",
            " -1.43897548e-01 -5.03428102e-01 -3.77037853e-01  2.62023080e-02\n",
            "  3.06610405e-01  1.50788454e-02  1.96452439e-01 -3.25846642e-01\n",
            "  1.72041029e-01  1.97953060e-01 -4.83851522e-01  1.13626495e-01\n",
            " -1.68236300e-01 -4.07259047e-01 -3.07668328e-01 -2.31200650e-01\n",
            " -2.22219318e-01 -5.47006071e-01 -2.19969228e-01 -4.80640203e-01\n",
            "  4.61127400e-01 -1.67241514e-01 -2.62571335e-01  1.37456730e-01\n",
            " -8.21128860e-03 -9.74780023e-02 -3.53935510e-01 -2.37425700e-01\n",
            " -3.20148826e-01 -5.66122830e-01 -3.52805257e-01  1.00752902e+00\n",
            " -2.46428013e-01 -2.73621138e-02 -6.83031697e-03 -8.94375741e-01\n",
            " -2.78094292e-01  1.37440709e-03 -9.72965285e-02 -5.64090490e-01\n",
            " -2.00808480e-01  2.60827299e-02  2.68492490e-01 -5.52295782e-02\n",
            "  4.18398380e-01 -6.39472157e-02  7.48621106e-01  2.03056499e-01\n",
            "  2.07898077e-02  3.43108594e-01 -7.27018833e-01 -2.11006552e-01\n",
            "  5.07258158e-03  1.43350035e-01 -8.70722055e-01  5.08902743e-02\n",
            " -6.71637654e-02  2.92184174e-01  2.69167840e-01 -6.96200013e-01\n",
            " -3.83792609e-01 -4.15004879e-01  1.33885920e-01 -3.15613687e-01\n",
            "  1.25324335e-02  3.42646167e-02 -4.12629724e-01 -8.91632065e-02\n",
            "  3.32164705e-01 -2.54898965e-01  4.68202770e-01  1.49571709e-02\n",
            "  4.87038285e-01 -1.33721441e-01 -6.21732712e-01  2.35356972e-01\n",
            "  6.47132844e-02 -2.71561354e-01 -4.01167780e-01  4.61352348e-01\n",
            "  3.42315376e-01 -4.56458963e-02 -3.07717711e-01  7.50717297e-02\n",
            "  1.36618957e-01  2.69026697e-01  8.87850747e-02  1.96376011e-01\n",
            "  7.53845751e-01 -1.71173498e-01  4.97614563e-01 -4.11141809e-04\n",
            "  8.73957425e-02 -5.78402042e-01  1.17040181e+00 -4.84410495e-01]\n"
          ]
        }
      ],
      "source": [
        "# el método `get_vector` permite obtener los vectores:\n",
        "vector_love = w2v_model.wv.get_vector(\"love\")\n",
        "print(vector_love)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umgpx7krE5Ep",
        "outputId": "0a5d9039-ee0c-4d96-aa92-6be3bf068456"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('love', 1.0),\n",
              " ('girls', 0.3476395010948181),\n",
              " ('usages', 0.33804160356521606),\n",
              " ('wedding', 0.3348587155342102),\n",
              " ('nantucketers', 0.330401211977005),\n",
              " ('chorus', 0.3296893239021301),\n",
              " ('nowadays', 0.325965017080307),\n",
              " ('stave', 0.31521379947662354),\n",
              " ('heroes', 0.3138481676578522),\n",
              " ('woods', 0.3135850131511688)]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# el método `most_similar` también permite comparar a partir de vectores\n",
        "w2v_model.wv.most_similar(vector_love)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-m3D_paE5Eq",
        "outputId": "5e1bc116-615c-4785-e8fe-e5a1bc8d7b58"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('girls', 0.3476395010948181),\n",
              " ('usages', 0.33804163336753845),\n",
              " ('wedding', 0.3348587155342102),\n",
              " ('nantucketers', 0.3304012417793274),\n",
              " ('chorus', 0.3296893537044525),\n",
              " ('nowadays', 0.325965017080307),\n",
              " ('stave', 0.31521379947662354),\n",
              " ('heroes', 0.3138481676578522),\n",
              " ('woods', 0.3135850131511688),\n",
              " ('mildness', 0.3114457130432129)]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# Palabras que MÁS se relacionan con...:\n",
        "w2v_model.wv.most_similar(positive=[\"love\"], topn=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_g8UVWe6lFmh"
      },
      "source": [
        "### 5 - Visualizar agrupación de vectores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "pDxEVXAivjr9"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import IncrementalPCA\n",
        "from sklearn.manifold import TSNE\n",
        "import numpy as np\n",
        "\n",
        "def reduce_dimensions(model, num_dimensions = 2 ):\n",
        "\n",
        "    vectors = np.asarray(model.wv.vectors)\n",
        "    labels = np.asarray(model.wv.index_to_key)\n",
        "\n",
        "\n",
        "    tsne = TSNE(n_components=num_dimensions, random_state=0)\n",
        "    vectors = tsne.fit_transform(vectors)\n",
        "\n",
        "    return vectors, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCCXtDpcugmd"
      },
      "outputs": [],
      "source": [
        "# Graficar los embedddings en 2D\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "#\n",
        "vecs, labels = reduce_dimensions(w2v_model)\n",
        "\n",
        "MAX_WORDS=200\n",
        "fig = px.scatter(x=vecs[:MAX_WORDS,0], y=vecs[:MAX_WORDS,1], text=labels[:MAX_WORDS])\n",
        "fig.show(renderer=\"colab\") # esto para plotly en colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irzuNkgxE5Eq"
      },
      "outputs": [],
      "source": [
        "# Graficar los embedddings en 3D\n",
        "\n",
        "vecs, labels = reduce_dimensions(w2v_model,3)\n",
        "\n",
        "fig = px.scatter_3d(x=vecs[:MAX_WORDS,0], y=vecs[:MAX_WORDS,1], z=vecs[:MAX_WORDS,2],text=labels[:MAX_WORDS])\n",
        "fig.update_traces(marker_size = 2)\n",
        "fig.show(renderer=\"colab\") # esto para plotly en colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7aNtgDxuE5Eq"
      },
      "outputs": [],
      "source": [
        "# También se pueden guardar los vectores y labels como tsv para graficar en\n",
        "# http://projector.tensorflow.org/\n",
        "\n",
        "\n",
        "vectors = np.asarray(w2v_model.wv.vectors)\n",
        "labels = list(w2v_model.wv.index_to_key)\n",
        "\n",
        "np.savetxt(\"vectors.tsv\", vectors, delimiter=\"\\t\")\n",
        "\n",
        "with open(\"labels.tsv\", \"w\") as fp:\n",
        "    for item in labels:\n",
        "        fp.write(\"%s\\n\" % item)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMM_SHSaZ9N-"
      },
      "source": [
        "### Alumno"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WivQZ3ZCZ9N_"
      },
      "source": [
        "- Crear sus propios vectores con Gensim basado en lo visto en clase con otro dataset.\n",
        "- Probar términos de interés y explicar similitudes en el espacio de embeddings (sacar conclusiones entre palabras similitudes y diferencias).\n",
        "- Graficarlos.\n",
        "- Obtener conclusiones."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}