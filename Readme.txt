Desafíos de Deep Learning y NLP

Este archivo describe las actividades y resultados de cinco desafíos realizados en el ámbito de Deep Learning y Procesamiento de Lenguaje Natural (NLP). Cada desafío aborda diferentes aspectos del análisis y modelado de texto utilizando diversas técnicas y arquitecturas.

Desafío 1: Análisis de Similitud Textual
En este desafío, se analizan textos para evaluar la similitud entre ellos. Utilizando técnicas de vectorización de palabras y calculando la similitud coseno, se determinan las relaciones de similitud entre diferentes fragmentos de texto. Este enfoque permite medir cuán similares son dos textos en función de la frecuencia y distribución de palabras dentro de ellos.

Desafío 2: Entrenamiento y Evaluación de Embeddings
Aquí, se entrenaron embeddings a partir del texto de "Moby Dick". Se exploró la representación en el espacio de embeddings y se evaluó la similaridad de palabras en dicho espacio. Esta tarea se centró en entender cómo se agrupan y relacionan las palabras según su contexto semántico en un corpus literario específico.

Desafío 3: Predicción de Próxima Palabra
En este desafío, se entrenaron modelos para la predicción de la próxima palabra en secuencias de texto, utilizando letras de canciones como corpus. Se evaluó la performance del modelo al modificar la complejidad de la red neuronal, experimentando con diferentes arquitecturas para observar su impacto en la capacidad predictiva.

Desafío 4: Respuestas de Chatbot con Esquema Encoder-Decoder
Se implementó un modelo basado en el esquema encoder-decoder para generar respuestas en un chatbot. Este enfoque se utilizó para procesar y generar respuestas a partir de secuencias de texto, demostrando la capacidad del modelo para entender y responder de manera coherente en un entorno conversacional.

Desafío 5: Sentiment Analysis con BERT
En este desafío, se utilizó el modelo BERT preentrenado para realizar análisis de sentimiento en reviews de aplicaciones. Se añadió complejidad a la red neuronal, específicamente en la parte entrenable final del esquema, para evaluar su performance en la clasificación de sentimiento. Se comparó la precisión del modelo al predecir tanto 3 como 5 clases de sentimiento, analizando su efectividad en distintas configuraciones.







